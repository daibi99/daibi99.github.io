[{"title":"Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection","url":"/2022/04/07/Adaptive%20Boundary%20Proposal%20Network%20for%20Arbitrary%20Shape%20Text%20Detection/","content":"　　本论文源自ICCV 2021，原文链接　　源码：https://github.com/GXYM/TextBPN\n一、本论文要解决的问题　　本文主要针对基于分割的方法来对任意形状文本检测存在的两个问题：一是基于分割的方法在分割图像中的相邻文本实例时往往会失败；二是在现有的基于分割的方法中，最终检测到的文本轮廓通常包含许多缺陷和干扰。\n二、针对上述问题的解决方案　　1.提出了一种用于任意形状文本检测的新型统一端到端可训练框架，该框架可以直接生成任意形状文本的精确边界，无需任何后处理。　　2.提出一种自适应边界变形模型，该模型可以执行迭代边界变形以细化文本边界。　　3.对数据集进行实验来证明上述模型与框架的性能。\n","categories":["ICCV 2021"]},{"title":"Data structure - Sort","url":"/2022/04/10/Data%20Structure%20Sort/","content":"　　本文主要做了数据结构——排序的知识整理。\n一、插入排序　　插入排序的基本思想是每次将一个待排序的记录按其大小插入到前面已排好序的子序列，直到全部记录插入完成。由此思想引申出三种插入排序算法：直接插入排序、折半插入排序和希尔排序。\n直接插入排序　　直接插入排序是最简单也是最直观的。我们要将元素E[i]插入到已有序的子序列E[1…i-1]，首先要在E[1…i-1]中按照元素大小找到元素E[i]插入的位置k，之后将E[k…i-1]中的所有元素后移一个位置，再将E[i]插入到E[k]。下面是直接插入排序的代码：\nvoid InsertSort(ElemType A[], int n)         //给定n个元素的数组进行排序\n{\n    int i, j;\n    for (i = 2; i &lt;= n; i++)\n    {\n        if (A[i] &lt; A[i - 1])\n        {\n            A[0] = A[i];\n            for (j = i - 1; A[0] &lt; A[j]; --j)   //这里的--j是先自减，再赋值，也就是说该for循环中的j为1, 但循环结束之后, j的值为0。\n                A[j + 1] = A[j];\n            A[j + 1] = A[0];\n        }\n    }\n}\n　　性能分析：直接插入排序使用了常数个辅助单元，所以空间复杂度为O(1)。最好情况下，给定的元素本就是有序的，因此在排序过程中只需要比较元素而不用移动元素，因此时间复杂度为O(n)。最坏情况下，给定的元素为逆序，每次插入不仅需要比较次数最大，而且需要移动的次数也是最大的，平均情况下，取最好与最坏情况的平均值为n^2/4。因此直接插入排序算法的时间复杂的是O(n^2)。由于每次插入元素时总是向前比较再移动，所以不会出现相同元素相对位置改变的情况，因此直接插入排序是一个稳定的排序方法。\n折半插入排序　　折半插入排序与直接插入排序不同的地方在于，直接插入排序是边比较边移动元素，而折半插入排序是先折半查找出元素的待插入位置，然后统一地移动待插入位置之后的所有元素。在对于顺序存储的线性表，所以查找有序子表时可以用折半查找来实现。下面是折半插入排序的代码：\nvoid InsertSort(ElemType A[], int n) {\n    int i, j, high, low, mid;\n    for (i = 2; i &lt;= n; i++)\n    {\n        A[0] = A[i];\n        low = 1, high = i - 1;\n        while (low &lt;= high)\n        {\n            mid = (low + high) / 2;\n            if (A[mid] &gt; A[0])\n            {\n                high = mid - 1;\n            }\n            else low = mid + 1;\n        }\n        for (j = i - 1; j &gt;= high + 1; --j)\n        {\n            A[j + 1] = A[j];\n        }\n        A[high + 1] = A[0];\n    }\n}\n　　性能分析：折半插入排序只减少了元素比较的次数，约为O(n\\log_2 n)，但是移动次数并未改变，因此折半插入排序的时间复杂的仍为O(n^2)。在数据量不是很大的排序表，折半查找能够表现出很好的性能，并且它是稳定的排序方法。\n希尔排序　　从直接排序的算法分析可以得知，当直接排序算法给定的序列有序且为正序时，时间复杂度可以提升到O(n)，也就是说基本有序的排序表和数据量不大的排序表用直接插入排序效率更高。希尔排序基于这个思路，把待排序表分割成若干个形如L[i,i+d,i+2d…i+kd]的子表，d为增量，对每个子表进行直接插入排序，当整个表中的元素已经基本有序时，再对全体记录进行一次直接插入排序。\nvoid ShellSort(ElemTyepe A[], int n)\n{\n    for (dk = n / 2; dk &gt;= 1; dk = dk / 2)\n        for (i = dk + 1; i &lt;= n; ++i)\n            if (A[i] &lt; A[i - dk]) {\n                A[0] = A[i];\n                for (j = i - dk; j &gt; 0 &amp;&amp; A[0] &lt; A[j]; j -= dk)\n                    A[j + dk] = A[j];\n                A[j + dk] = A[0];\n            }\n}\n　　性能分析：希尔排序只用了常数个辅助单元，空间复杂度为O(1)。它的时间复杂度依赖于增量序列的函数，这是数学上的问题，分析较为困难，最坏的时间复杂度为O(n^2)。当相同关键字被划分到不同子表的时候，可能会改变相对次序，因此希尔排序是不稳定的算法。\n二、交换排序　　交换排序的意思是根据序列中两个元素的关键字的比较结果来交换这两个元素在序列中的位置，这里主要介绍冒泡排序算法和快速排序算法。\n冒泡排序　　冒泡排序的基本思想是，从后往前（或是从前往后），比较两两元素的值，若是逆序，则交换两元素位置，直到序列比较完成，该过程就很像第一趟排序把最小的元素从后面“浮上来”，然后不再参与比较，第二趟就继续把最小的浮上来，也就是说每一轮冒泡排序，都有一个最小的数从待排序序列中“浮”出来，重复此过程直到一轮比较下来没有发生元素交换，说明已经有序。冒泡排序的代码如下：\nvoid BubbleSort(ElemType A[], int n)\n{\n    for (int i = 0; i &lt; n - 1; i++)\n    {\n        flag = false;\n        if (int j = n - 1; j &lt; i; j--)\n        {\n            if (A[j - 1] &gt; A[j])\n                swap(A[j - 1], A[j]);    //temp交换\n                flag = true;\n        }\n        if (falg == false)         //没有交换，则代表表已经有序\n            return;      \n    }\n}\n　　性能分析: 空间复杂度为O(1)。最好情况是原本有序，只做一遍比较，最坏情况为原本逆序，时间复杂度为O(n^2)。\n快速排序　　快速排序的思想是基于分治算法的，它从待排序序列L[1…n]中任取一个枢纽pivot，通过一轮快速排序将原排序系列分为L[1…k-1]和L[k+1..n]，其中L[1…k-1]的元素都比pivot小，L[k+1…n]中的元素都大于等于pivot，这样pivot就被放在了最终位置上，也就是说，一趟快速排序结束，一定会有一个元素会被放在最终位置。快速排序算法的代码如下：\nvoid QuickSort(int A[], int low, int high)\n{\n    if (low &lt; high)\n    {\n        int pivotpos = Partition(A, low, high);\n        QuickSort(A, low, pivotpos - 1);        //递归排序划分子表\n        QuickSort(A, pivotpos + 1, high);\n    }\n}\nint Partition(int A[], int low, int high)\n{\n    int pivot = A[low];\n    while (low &lt; high)\n    {\n        while (low &lt; high &amp;&amp; pivot &lt;= A[high])\n            --high;\n        A[low] = A[high];\n        while (low &lt; high &amp;&amp; pivot &gt;A[low])\n            ++low;\n        A[high] = A[low];\n    }\n    A[low] = pivot;\n    return low;            //返回存放枢纽的最终位置\n}\n　　性能分析：因为算法调用了递归工作栈，其空间复杂度与调用次数有关，最好情况下为O(\\log_2 n)，最坏情况下要n-1次，平均情况下空间复杂度为O(\\log_2 n)。　　试想对一个基本有序的序列进行快速排序，选取了第一个元素作为枢纽，而它本就是序列中最大的元素了，因此划分出的两个子表中元素个数分别是0,n-1，但是还是要对两个子表进行快排，就造成了时间的大量浪费，因此快速排序不适合基本有序的序列。最理想条件下则是分割成两个等量长度的子序列，也就是选择枢纽的值尽可能把序列平等分割。这时候快排的时间复杂度为O(n\\log_2 n), 需要注意的是，快速排序算法是所有内部排序算法中平均性能最优的。\n三、选择排序简单选择排序　　简单选择排序的基本思想是：每i次排序都在待排序的n-i+1个元素中选择一个最小的元素，作为有序队列的第i个元素，直到n-1次排序结束。简单选择排序算法的代码如下：\nvoid SeleceSort(int A[], int n)\n{\n    for (int i = 0; i &lt; n; i++)\n    {\n        int min = i;\n        for (int j = i + 1; j &lt; n; j++)\n                if (A[j] &lt; A[min])\n                min = j;\n        if (min != i)\n            swap(A[i], A[min]);\n    }\n}\n　　性能分析：该算法空间复杂度为O(1)，但是其比较次数与初始序列无关，导致其时间复杂度始终为O(n^2)。并且简单选择排序是一个不稳定的算法。\n堆排序　　我们可以将堆视为一颗完全二叉树，当满足左右孩子结点均小于等于双亲结点的时候，我们称之为大根堆，当左右孩子结点均大于等于双亲结点的时候，我们称之为小根堆。我们以大根堆为例，排序思路很简单，就是输出堆顶元素，它一定是最大的，输出之后，把堆底元素送入堆顶，但是此时已经不满足大根堆了，因此我们要重组大根堆，接着继续输出堆顶元素。因此我们主要的问题有两个：一是如何将无序序列构造成大根堆；二是输出大根堆元素后，如何将剩余的元素调整为大根堆。建立大根堆的算法如下：\nvoid BuildMaxHeap(int A[], int len)\n{\n    for (int i = len / 2; i &gt; 0; i--)\n        HeadAdjust(A, i, len);\n}\nvoid HeadAdjust(int A[], int k, int len)\n{\n    A[0] = A[k];\n    for (int i = k * 2; i &lt;= len; i *= 2) \n    {\n        if (i &lt; len &amp;&amp; A[i] &lt; A[i + 1])\n            i++;\n        if (A[0] &gt;= A[i])  break;\n        else \n        {\n            A[k] = A[i];\n            k = i;\n        }\n    }\n}\n　　性能分析：空间复杂度为Ｏ(1), 首先建堆时间为O(n)，调整时间为O(h)，所有平均时间复杂度为O(n\\log_2 n)。另外，堆排序是不稳定的排序算法。\n","categories":["Data Structure"]},{"title":"Computer Organization - Chapter One","url":"/2022/04/11/Computer%20Organization%20-%20Chapter%20One/","content":"　　本文主要做了计算机组成原理——冯·诺依曼计算机的知识整理\n一、硬件结构　　冯·诺依曼计算机由运算器、控制器、存储器、输入设备和输出设备组成，其中运算器和控制器被合称为中央处理器（Central Processing Unit, CPU)。\n运算器　　运算器的主要功能是对数据或数据进行处理或运算，并暂存处理或运算结果。　　因为最频繁的运算为算术运算和逻辑运算，而算术运算是在逻辑运算的基础上实现的，所有这两种运算常用一个部件实现，我们将其称为算术逻辑单元（Arithmetic Logic Unit, ALU）。但是由于ALU只处理整型数据，而且整数和实数的运算方法不同，所有运算器也会增设浮点运算部件FPU（Float Point Unit）用来处理实数。　　ALU的核心是加法器，它不仅可以实现加减等双目算术运算，也可以实现与、或、非等双目或是单目逻辑运算，因此ALU有两个数据入端、一个数据出端。为了保存运算结果，在运算器中还会有若干个寄存器，它们通常被称为寄存器堆、寄存器组或寄存器文件，它们不仅可以保存数据，还可以保存地址、状态等　　可见，运算器一般由ALU、FPU、寄存器等组成。\n控制器　　控制器的主要功能是指挥和控制各部件协调工作，来实现程序的自动执行。　　通常来说，程序执行过程是循环的指令执行过程，指令执行过程分为取指令、分析指令和执行指令三个阶段，循环变量为指令地址，下条指令地址由当前指令产生。　　为了实现指令的循环，控制器需要有两个专用寄存器，一个是程序计数器PC（Program Counter, PC）用来存放作为循环变量的指令地址；另一个称为指令寄存器（Instruction Register, IR）用来存放当前指令的内容。也就是说，取指阶段总是用PC的内容为地址去存储器取指令，然后存放到IR中。　　另外，为了实现当前指令的功能，控制器还需要指令译码器（Instruction Decode，ID）用来分析IR中的指令的操作类型及操作数类型，再用控制单元（Control Unit，CU）产生部件控制信号。　　可见，控制器一般由PC，IR，ID，CU等组成。\n存储器　　存储器的主要功能是存储信息，可以通过操作实现信息的写入和读出。　　存储器的存储空间由若干个存储单元构成，每个存储单元由多个存储元构成，每个存储元可以存储一位二进制信息（0或1）。存储器的容量＝存储单元个数 x 存储单元长度。由于存储器是按地址进行访问，所以访问的地址为存储单元的地址，存储器的外部引脚必须包含地址引脚、命令引脚、数据引脚。　　对存储器的操作一般只有读和写。读操作时，先向存储器发出地址及读命令，存储器根据地址来选择存储单元，并将所选存储单元的存储字送到数据引脚。写操作时，同样需要向存储器发出地址及写命令，然后向存储器发出所写数据，存储器根据地址来选择存储单元，并将数据引脚上的数据写入存储单元。\n二、设备互联的实现总线结构　　总线也就是设备间进行信息传输的公共信号线，总线上的设备通过地址（设备编号）来进行识别。系统总线通常由地址总线、数据总线、控制总线三种信号线组成。　　总线方式的优点是传输控制简单、可扩展性好，因为它对所有设备适用，仅仅是传输的目标地址不同而已，因此传输控制极为简单。另外，新设备连接到总线上，只需要它的地址与总线上的设备的地址不同即可。总线方式的缺点也很明显，就是需要分时进行信息传输，因为总线信号线是共用的，所有任何时候只能有一个设备在发送状态，其他设备都只能处于接收状态。　　为了将外设连接到总线上，需要在外设与总线间增设连接点了，也就是I/O接口，它的主要功能是实现数据缓冲、格式转换、通信控制。\n总线传输　　总线上的不同设备通过地址进行识别，对于主设备而言，总线命令只有读、写两类。　　第①步，主设备发送地址和命令，所有从设备判断自己是否是目标设备，若是则响应操作。第②步，当命令为读时，从设备发送数据、发送状态（完成），主设备根据状态信号接收数据；命令为写时，主设备发送数据，从设备接受并写入数据、发送状态（完成）。传送完成后，各自撤销所发信号。由于需要处理操作命令，读操作第①步时间稍长，写操作第②步时间稍长。\n三、计算机的工作方式程序的执行顺序　　冯·诺依曼计算机都采用存储程序工作方式，存储程序工作方式的基本思想是：程序和数据预先放在存储器中，程序执行时，自动、逐条从存储器中取出指令并执行。　　因为程序需要放在主存中才能执行，而主存是按地址访问的，所以程序的空间需要按主存单元空间长度进行编址，由于生成程序时并不知道程序运行时在主存的地址，所以一般从0开始编址，又称逻辑地址。程序由多条指令构成，每条指令占一个或几个存储单元，指令地址一般用其所占第一个存储单元的地址表示，指令地址和数据地址由两重含义，在程序中的地址叫逻辑地址，在主存中的地址称为物理地址。　　顺序型指令的下条指令地址=当前指令地址+“1”，1表示一条指令所占存储单元个数。转移型指令下条指令地址=当前指令的操作结果或者=当前指令地址+“1”。\n程序的执行机制　　取指阶段的功能是，用PC的内容作为地址从内存中读出指令，并放入IR；分析指令阶段的功能是，通过ID分析IR中内容包含的操作类型、操作数信息，再用CU产生部件控制信号；执行指令阶段的功能是，根据指令分析结果，实现相应的约定操作。　　对该执行机制的优化也就是想办法减少每轮循环的时间，对于顺序型指令，下条指令地址计算与当前指令内容无关，则可以将PC=（PC）+“1” 放在取指阶段或者译码阶段。对于转移型指令，下条指令地址的计算放在执行阶段，也可以提高性能。　　程序执行有两个初始条件：一是程序被调入主存，二是程序首条指令地址被置入PC。\n四、计算机系统的性能指标机器字长　　机器字长又称CPU字长，指CPU一次能处理数据的二进制位数。机器字长越长，运算精度越高。若机器字长较短，则位数较多的数据运算需要拆分几次运算。\nCPU主频　　CPU主频是指CPU主时钟信号的频率，它是时钟周期的倒数，它的高低很大程度上决定了CPU工作速度。\n存储容量　　CPU可以直接访问主存，所以CPU寻址空间受到主存地址空间的影响，也就影响了CPU地址引脚的位数。CPU地址引脚需要按照主存地址空间来设置，与主存的配置容量无关，例如主存按字节编址，4GB，则主存地址为32位，CPU寻址空间也为32位。\n响应时间　　响应时间指的是执行时间，指任务从提交到完成所花的全部时间，包括CPU运算，贮存访问、I/O操作、操作系统开销等所有的时间，T_{响应}=T_{cpu}+T_{等待}。因为现代计算机当程序等待I/O操作完成时，CPU会转去执行其他程序，所以等待时间一般忽略通过比较CPU时间来比较计算机性能。\n吞吐率　　MIPS（Million Instructions Per Second) 与MFLOPS (Million Floating-Point Operations Per Sencond) ，吞吐率=n个任务的总工作量/完成n个任务的总时间。\n","categories":["Computer Organization"]},{"title":"Task-agnostic Video-Language Model Pre-training for Video Understanding","url":"/2022/04/17/Task-agnostic%20Video-Language%20Model%20Pre-training%20for%20Video%20Understanding/","content":"　　本论文源自ICCV 2021，原文链接　　源码：https://github.com/pytorch/fairseq/tree/main/examples/MMPT\n本论文解决的现有问题　　现有的预训练是针对特定任务的，通过采用需要两种模态的单一交叉模态编码器，这限制其用于检索式任务，或采用两个单模态编码器进行更复杂的多任务学习，这限制早期交叉模态融合。　　现有的视频和语言预训练是特定于任务的，它们采用（1）需要跨模态推理(例如视频字幕)的任务的单个跨模态编码器，或（2）多个单模态编码器/解码器，来结合需要单独嵌入每个模态的特定任务。相反，本文提出了一种称为视频语言模型（video language model，VLM），证明了任务无关模型的预训练是可能的，该模型可以接受文本、视频或两者作为输入。\n针对上述问题的解决方案　　1.提出了一种简单的、任务无关的多模态预训练方法，可以接受视频或文本输入，或同时接受视频或文本输入，用于各种最终的下游任务。　　2.引入了新的预训练mask方案，可以更好地跨模态混合（例如，通过强制文本mask来预测最近的视频嵌入），同时保持可分性（例如，有时只需要单模态预测，而不使用所有输入）。　　3.实验论证上述方案的可行性。\n","categories":["ICCV 2021"]},{"title":"Fishing Master","url":"/2022/04/07/Finshing%20Master/","content":"　　This is a question from CCPC 2019, the problem is described as follows:\n　　Heard that emt is a fishing MASTER, you want to acknowledge him as your mentor. As everybody knows, if you want to be a MASTER’s apprentice, you should pass the trial. So when you find fishing MASTER emt, the trial is as follow: There are n fish in the pool. For the i - th fish, it takes at least ti minutes to stew(overcook is acceptable). To simplify this problem, the time spent catching a fish is k minutes. You can catch fish one at a time and because there is only one pot, only one fish can be stewed in the pot at a time.  While you are catching a fish, you can not put a raw fish you have caught into the pot, that means if you begin to catch a fish, you can’t stop until after k minutes; when you are not catching fish, you can take a cooked fish (stewed for no less than ti) out of the pot or put a raw fish into the pot, these two operations take no time. Note that if the fish stewed in the pot is not stewed for enough time, you cannot take it out, but you can go to catch another fish or just wait for a while doing nothing until it is sufficiently stewed.Now emt wants you to catch and stew all the fish as soon as possible (you definitely know that a fish can be eaten only after sufficiently stewed), so that he can have a satisfying meal. If you can complete that in the shortest possible time, emt will accept you as his apprentice and say “I am done! I am full!”. If you can’t, emt will not accept you and say “You are done! You are fool!”. So what’s the shortest time to pass the trial if you arrange the time optimally?\nSolving Idea:　　Ideally, the time it takes res = m + the sum of the time to cook all the fish.But in some cases, we can’t just go fishing when we cook every fish, so we need to cook some fish for more time to catch some extra fish. What we have to do is to reduce the extra fish as much as possible. time spent. When we cook the ith fish, the number of fish we can fish without spending any extra time is a[i] / m, and the remaining time is a[i] % m, we can count whether we can fish without spending any extra time to catch all the fish, if not, we need to spend m - a[i] % m more time after the fish with the most time remaining is cooked.\nSolution:\n#include &lt;bits/stdc++.h&gt;\nusing namespace std;\ntypedef long long ll;\n#define rep(i, n) for (int i = 1; i &lt;= n; ++i)\nconst int N = 1E5 + 10;\nint a[N];\nint main()\n    &#123;\n        int t; cin &gt;&gt; t;\n        while (t--) &#123;\n            vector&lt;int&gt; b;\n            int n, m; scanf(&quot;%d %d&quot;, &amp;n, &amp;m);\n            ll res = m; int cou = 1; \n            rep(i, n) scanf(&quot;%d&quot;, &amp;a[i]), res += a[i], cou += a[i] / m, b.push_back(a[i] % m);\n            sort(b.begin(), b.end(), greater&lt;int&gt;());\n            for (int i = 1; i &lt;= n - cou; ++i) res += m - b[i - 1];\n            cout &lt;&lt; res &lt;&lt; endl;\n        &#125;\n        return 0;\n    &#125;\n","categories":["Algorithm Practice"]},{"title":"Data Structure－Graph","url":"/2022/04/08/Data%20Structure%20Graph/","content":"　　本文主要做了数据结构——图相关的知识整理。\n一、图的基本术语图　　图是由有限非空的顶点集合与表示顶点之间关系的集合组成的，也就是顶点集V与边集E，我们将图G记作G = (V , E)。另外，我们用|V|表示图的顶点数，|E|表示图的边数。\n有向图　　顶点与顶点之间的连接（弧）是有向的，一般用从一个顶点指向另一个顶点的有序对来表示弧，例如有序对，其中ｖ,w是顶点，则就是代表从v到w的一条弧。举个简单的例子：G = (V,E) ;  V = { 1,2,3 }; E = {&lt;1,2&gt;,&lt;2,3&gt;,&lt;1,3&gt;};\n无向图　　顶点与顶点之间的连接（边）是无向的，这时我们就用无序对来表示边，例如(v,w)就表示了顶点v与顶点w之间相关联。\n简单图　　简单图需要满足两个条件，一是不能有重复的边；二是不存在顶点到自身的边。\n完全图　　完全图要求任意两个顶点之间都存在边(或者弧)。对于无向图来说，|E|的取值范围为0—n(n-1)/2, 有n(n-1)/2条边的无向图就称作完全图。对于有向图，|E|的取值范围为0—n(n-1), 有n(n-1)条边的有向图就称作有向完全图。\n连通，连通图与连通分量　　连通是针对无向图而言的，若无向图中顶点v到顶点w有路径存在，我们就称v和w是连通的。若无向图任意两个顶点都是连通的，我们就称无向图G为连通图。无向图中的极大连通子图被称做连通分量。也就是说，若一个无向图有n个顶点，但是它的边数小于n-1，那么此图必是非连通图。若一个无向图有n个顶点，它是非连通图，那么它最多只能有(n-1)(n-2)/2条边。\n强连通图，强连通分量　　强连通是针对有向图而言的，若有向图中顶点v与顶点w，顶点w与顶点v均有路径存在，则这两个顶点就是强连通的。若有向图中每一对顶点都是强连通的，则称之为强连通图。也就是说n个顶点的有向图，至少要有n-1条弧才能成为强连通图。\n度　　在无向图中，顶点v的度是指依附于顶点v的边的条数，也就是说无向图的全部顶点的度总和等于边数的两倍，因为每条边都与两个顶点相关联。对于有向图，度分为出度与入度，出度是指从该顶点出发指向别的顶点的弧的数量，入度则是指指向该顶点的弧的数量。也就是说，有向图每个顶点的入度之和与出度之和都等于边数e。\n环　　若顶点之间的路径第一个顶点与最后一个顶点相同，则称该路径为环。若一个图有n个顶点，且大于n-1条边，则该图一定有环。\n二、图的存储邻接矩阵　　邻接矩阵是指用一个一维数组来存储顶点，用一个二维数组来存储顶点之间的关系。例如n个顶点的图就会构成一个A_{n \\times n}的矩阵。若v_i到v_j之间有边，则A_{ij}的值就为1，否则为0。由此可知，图的邻接矩阵是唯一的，无向图的邻接矩阵是一个对称矩阵，且邻接矩阵适合存储稠密图，因为它的存储空间是由顶点个数决定的，空间复杂度为O(n^2)，若是稀疏图则没必要花费那么大的空间来存储边的关系。\n邻接表　　与邻接矩阵相比，邻接表就适合存储稀疏图。我们为图的每一个顶点创建一个单链表，并将该边指向的顶点插入到该链表中，因此，无向图的邻接表空间复杂度为O(|V|+2|E|)，有向图则为O(|V|+|E|)。邻接表并不唯一，因为每个顶点对应的单链表，各个顶点的链接次序是任意的。\n十字链表　　十字链表是针对有向图的链式存储结构。十字链表为有向图中每个顶点创建了一个节点，每条弧也创建了一个结点，弧结点除去信息有4个域: 尾域、头域、链域hlink指向弧头相同的下一条弧、链域tlink指向弧尾相同的下一条弧。顶点结点除去信息域还有firstin 和firtsout 两个域，分别指向以该顶点为弧头或弧尾的第一个弧结点。注意顶点之间是顺序存储的，十字链表之所以这么设计，是为了方便找到以v_i为尾或者为头的弧，因而容易求顶点的入度和出度。十字链表不唯一，但一个十字链表表示确定一个图。\n邻接多重表　　邻接多重表是针对无向图的链式存储结构。因其查找顶点间是否连通以及删除操作效率较低，应用极少，不做叙述。\n三、图的遍历Breadth-First-Search(BFS)　　广度优先算法（BFS）算法的基本思想是，从给定顶点v开始，依次访问v的（还未被访问过的）邻接顶点w_1、w_2、w_3…，然后从w_1、w_2、w_3开始，重复上述的过程，直到所有的顶点都被访问，因此该算法需要借助一个辅助队列来记录正在访问顶点的下一层顶点。需要注意的是，每个顶点只能被访问一次。BFS在数据结构中可以用在Dijkstra单源最短路径算法和Prim最小生成树算法。BFS伪代码如下：\nbool visited[Max_v];      //标记访问数组\nvoid BFSTraversre(Graph G)\n{\n    for（i = 0; i &lt; G.vexnum; i++)\n         visited[i] = false;          //初始化访问数组\n    InitQueue(Q);            \n    for (i = 0; i &lt; G.vexnum; i++)\n        if (!vsisted[i])\n            BFS(G, i);      //若顶点未被访问过，则对其进行BFS\n}\n\nvoid BFS(Graph G, int v)\n{\n    visit(v);\n    visited[v] = true;             //标记为已访问 \n    Enqueue(Q, V);                //v进队\n    while (!isEmpty(Q))\n    {\n        DeQueue(Q, v);\n        for (w = FirstNeighbor(G, v); w &gt;= 0; w = NextNeighbor(G, v, w)    //v的邻接顶点入队\n        {\n            if(!visited[w])\n                visit[w];\n                visited[w]=TRUE;\n                EnQueue(Q,w);\n        }\n    }\n}\n　　BFS算法需要借助辅助队列，而且每个顶点都需要入队一次，所以空间复杂度是O(|V|)。当图采用邻接表存储时，每个顶点需要被访问一次，而访问该顶点的邻接顶点只需要对单链表进行操作，因此时间复杂度为O(|V|+|E|)。当图采用邻接矩阵存储时，查找每个顶点的邻接顶点所需时间为O(|V|)，所以总时间复杂度为O(|V^2|)。\nDepth-First-Search(DFS)　　深度优先算法（DFS）的基本思想是，从给定顶点v出发，访问与v邻接的且未被访问过的顶点w，再从w出发，访问与w邻接且未被访问过的顶点w_1，重复此过程，当不能再往下访问时，依次退回到最近被访问的顶点，若他还有邻接顶点未被访问过，则从该点开始继续上述过程，直到所有顶点被访问。因此，DFS算法需要借助递归工作栈来返回最近被访问顶点的值。DFS伪代码如下：\nbool visited[Max_v];      //标记访问数组\nvoid DFSTraversre(Graph G)\n{\n    for（i = 0; i &lt; G.vexnum; i++)\n    visited[i] = false;          //初始化访问数组\n    for (i = 0; i &lt; G.vexnum; i++)\n        if (!vsisted[i])\n            DFS(G, i);      //若顶点未被访问过，则对其进行DFS\n}\n\nvoid DFS(Graph G, int v)\n{\n    visit(v);\n    visited[v] = TRUE;\n    for(w=FirstNeighbor(G,v);w&gt;=0;w=NextNeighbor(G,v,w))\n        if (!visited[w]) {\n            DFS(G, w)\n        }\n}\n　　DFS算法需要用到递归工作栈，因此空间复杂度为O(|V|)。当图用邻接表存储时，查找所有顶点需要O(|V|+|E|)。当图用邻接矩阵存储时，每个顶点和其邻接结点的查找都需要O(|V|)，故总时间复杂度为O(|V^2|)。\n四、遍历算法的应用及拓展连通性和路径查找　　遍历算法可以判断图的连通性。例如对于一个无向图，若图是连通的，则从任意顶点出发，仅需一次遍历就可以访问所有的结点。若图非连通，则只能访问到该图的连通分量的结点。　　上文中DFS算法使用了递归，那么非递归的DFS应该怎么设计呢？首先我们需要一个栈，用来存储访问过的结点信息，因为当我们不能再往下访问时，需要回退到最近访问的结点，这个特性刚好可以用栈来实现，我们在访问一个顶点时，要把它放进栈中，当栈非空时，将其取出，再将其邻接的结点放进去，重复上述过程。DFS非递归代码如下：\nbool visited[Max_v]; \nvoid DFSTraversre(Graph G)\n{\n    for（i = 0; i &lt; G.vexnum; i++)\n              visited[i] = false;  \n    InitStack(S);\n    for (i = 0; i &lt; G.vexnum; i++)\n        if (!vsisted[i])\n            DFS(G, i); \n}\n\nvoid DFS(Graph G, int v)\n{\n    Push(S, v);\n    visited[v] = true;\n    while (!isEmpty(S))\n        a = Pop(S);\n            visit[a];\n        for (w = NextNeighbor(G, a); w &gt;= 0; w = NextNeighbor(G, a, w)) {\n            if (!visited[w])\n                Push(S, w);\n                    visited[w] = true;\n        }\n}\n　　遍历算法还可以应用到查找有向图中是否存在顶点v到顶点w的路径。下面分别用BFS与DFS算法演示：\n　　BFS:\nint BFS(Graph G, int v, int w)\n{\n    InitQueue(Q);\n    Enqueue(Q, v);\n    while (!isEmpty(Q))\n        Dequeue(Q, u);            //u为队头元素\n            visited[u] = true;\n        if (u == w)\n            return 1;\n        for (p = NextNeighbor(G, u); p &gt;= 0; p = NextNeighbor(G, u, p))\n        {\n            if (p == w)         //p=w查找成功，返回1\n                return 1;\n            if (!visited[p])    //否则入队\n                EnQueue(Q, p);\n                    visited[p] = 1;\n        }\n}\n　　DFS:\nvoid DFS(Graph G, int v, int w, bool reach)\n{\n    if (v == w) \n    {\n        reach = true;\n        return;\n    }\n    visit[v] = true;\n    for (i = NextNeighbor(G, v); i &gt;= 0; i = NextNeighbor(G, v, i)) \n    {\n        if (i == w) {\n            reach = true;\n            return;\n        }\n        DFS(G, i, w, reach);\n    }\n}\nPrim/Kruskal最小生成树算法　　最小生成树是指包含该图所有顶点并且有着尽可能少的边的树。也就是说对于一个生成树，它的边数等于顶点数减一，如果去掉它的一条边，它会变成非连通图，增加一条边，它就形成一条回路。Prim算法与Kruskal算法都是基于贪心算法的策略。　　Prim算法的基本思想：创建一个空树，选取一个顶点归入树，这时树中就只有一个顶点，然后选取其邻接顶点中与之相连的边权值最小的顶点并入树T，这时T有两个顶点，这时再从其余顶点中选取与该T相连的权值最小的顶点归并到T中，直到所有顶点都在T中。因为每个顶点都至少需要访问与之相连权值最小顶点的顶点一次，故Prim算法的时间复杂度为O(|V^2|)，因此Prim算法更适合边稠密的图。　　Kruskal算法的基本思想：初始状态，将一个图视为只有顶点没有边的独立的连通分量，然后按照边的权值从小到大的排序，不断选择未被选取过且权值最小的边，若该边依附的顶点落在T中不同的连通分量上，则将此边加入T，否则舍弃继续寻找下一条权值最小的边，直到所有顶点都在T中。该算法最大的开销在于边权值的排序，一般我们使用堆排序来解决，时间复杂度为O(|E|\\log_2 {|E|})，因此Kruskal适合顶点多而边稀疏的图。\nDijkstra单源最短路径算法　　之前介绍遍历的应用中可以查找路径，但那是对于无权图而言，而对于带权图（边有权值，可以想象为距离），我们常常需要寻找带权路径长度最短的那一条路径，并称之为最短路径。　　算法思想：Dijkstra算法设置一个集合来记录已求得最短路径的顶点，初始时把源点v0放入S，每次并入一个新顶点vi时，都要修改源点v0到集合S中其余顶点的当前最短路径值。这里设置了两个辅助数组dist[]和path[]，dist[]用来记录v0到其他顶点的当前最短路径长度，初态，若源点v_0到v_i有弧，则dist[i]为弧的权值，否则dist[i]为无穷大。path[i]用来记录原点到顶点i之间的最短路径的前驱结点，算法结束后可以追溯到v_0到v_i的最短路径。　　初始化集合S为{0}，dist[i]=arcs[0][i]，下一步，我们要选出满足dist[j]=Min{dist[i]}的顶点J，也就是选出与v0相连的所有顶点中，带权路径长度最短的那一条，并将其并入集合S，另外，还要修改v0到S（顶点vj并入之后）内其余顶点的路径长度。重复此过程，直到所有顶点并入S。该算法不适用于有权值为负的边，其时间复杂度为O(|V^2|)。\nFloyd多源最短路径算法　　算法思想：Floyd算法递推产生一个n阶方阵序列从A^{-1}，A^0...A^{n-1},其中方阵A用来记录顶点之间的路径长度，而上标k=-1，0，n-1指的是顶点之间绕行k个顶点的路径长度。也就是说，在初始状态，若顶点之间有路径，则在方阵中记录路径长度，若无路径，则记录无穷大，之后再来探究顶点之间若是绕行另一个顶点，会不会有路径或者原本的路径减小，此时就要在方阵中进行更新。Floyd算法的时间复杂度为O(|V^3|)。其实用Dijkstra算法轮流将每个顶点作为源点，并在所有边权值为负时运行一次，也可以解决每对顶点之间的最短路径问题。\n拓扑排序　　当图用来代表工程活动，顶点表示活动，我们用有向边&lt;v_i，v_j&gt;代表v_i必须先于v_j活动的关系，并将这种图记为AOV网。我们构建拓扑排序的步骤一般是：首先从AOV网选择一个没有前驱的顶点并输出，然后从网中删除该顶点以及以它为起点的有向边，重复上述步骤直到当前AOV网为空。\n关键路径　　与AOV网相似，AOE网是指整个图中仅有一个入度为0的顶点，称为源点，仅有一个出度为0的顶点，称为汇点。在AOE网上，有些活动是可以并行进行的，从源点到汇点的路径可能有很多条，并且这些路径的长度可能不同。完成所有路径上活动所需的时间可能不同，但所有路径上的活动都已经完成，整个工程才算结束。因此我们将从源点到汇点的所有路径中，具有最大路径长度的路径成为关键路径。　　求解关键路径的步骤如下：从源点出发，拓扑排序求其余顶点的最早发生时间v_e；之后从汇点出发，按逆拓扑排序求其余顶点的最迟发生时间v_l。根据v_e和v_l的值分别计算出所有弧的最早开始时间e和最迟开始时间l。若e-l=0，则这个弧就是关键路径中的弧。\n","categories":["Data Structure"]}]